{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "local.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l-vwd4-Pqh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "87ed6223-8c92-408a-ff6a-fbc2101f14c5"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkObV8zODxQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "314d49ce-1fec-4525-8580-f061ddb4749e"
      },
      "source": [
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "\n",
        "def getSynonyms(word1):\n",
        "    synonymList1 = []\n",
        "    for data1 in word1:\n",
        "        wordnetSynset1 = wn.synsets(data1)\n",
        "        tempList1=[]\n",
        "        tempList1.append(data1)\n",
        "        #print(wordnetSynset1)\n",
        "        \n",
        "        for synset1 in wordnetSynset1:\n",
        "            synLemmas = synset1.lemma_names()\n",
        "            for i in range(len(synLemmas)):\n",
        "                word = synLemmas[i].replace('_',' ')\n",
        "                if word not in tempList1:\n",
        "                    tempList1.append(word)\n",
        "        \n",
        "        spl = False            \n",
        "        if(data1 == \"what\"):\n",
        "            spl = True\n",
        "            wordnetSynset1=wn.synsets(\"define\")\n",
        "        elif(data1 == \"explain\"):\n",
        "            spl = True\n",
        "            wordnetSynset1=wn.synsets(\"describe\")            \n",
        "        elif(data1 == \"difference\"):\n",
        "            spl = True\n",
        "            wordnetSynset1=wn.synsets(\"distinguish\")\n",
        "        elif(data1 == \"advantage\"):\n",
        "            spl = True\n",
        "            tempList1.extend([\"pros\",\"merits\"])\n",
        "            wordnetSynset1=wn.synsets(\"benefits\")\n",
        "        elif(data1 == \"disadvantage\"):\n",
        "            spl = True\n",
        "            tempList1.append(\"cons\")\n",
        "            wordnetSynset1=wn.synsets(\"demerits\")\n",
        "            \n",
        "        if(spl):    \n",
        "            for synset1 in wordnetSynset1:\n",
        "                synLemmas = synset1.lemma_names()\n",
        "                for i in range(len(synLemmas)):\n",
        "                    word = synLemmas[i].replace('_',' ')\n",
        "                    if word not in tempList1:\n",
        "                        tempList1.append(word)\n",
        "        synonymList1.append(tempList1)\n",
        "    return synonymList1\n",
        "\n",
        "print(getSynonyms([\"demerits\"]))\n",
        "\n",
        "def getSynonymsIndex(word1, word2):\n",
        "    len1 = len(word1)\n",
        "    len2 = len(word2)\n",
        "    \n",
        "    if(len1+len2 == 0):\n",
        "        return 0.5\n",
        "    \n",
        "    counter = 0\n",
        "    d2 = getSynonyms(word2)\n",
        "    #print(d2)\n",
        "    \n",
        "    for i in range(len(word1)):          \n",
        "        for k in range(len(d2)):\n",
        "            if word1[i] in d2[k]:\n",
        "                counter += 1\n",
        "                d2.pop(k)\n",
        "                break\n",
        "\n",
        "    syn_index = counter*2 / (len1 + len2)\n",
        "    return syn_index\n",
        "\n",
        "#print (getSynonymsIndex(word1, word2))     \n",
        "\n",
        "\n",
        "def getMatchingIndex(word1, word2):\n",
        "    len1 = len(word1)\n",
        "    len2 = len(word2)\n",
        "    \n",
        "    if(len1+len2 == 0):\n",
        "        return 0.5\n",
        "    \n",
        "    counter = 0\n",
        "    for i in word1:\n",
        "        for j in word2:\n",
        "            if(i in j):\n",
        "                counter+=1\n",
        "                word2.remove(j)\n",
        "                break\n",
        "    match_index = counter*2 / (len1 + len2)\n",
        "    return match_index    "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['demerits', 'demerit', 'fault']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTL7ki_OP7bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "def preProcess(sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    sentence = re.sub(r'[^A-Za-z\\s]+', ' ', sentence)\n",
        "    sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
        "\n",
        "\n",
        "    #lemmatize\n",
        "    tokens = nltk.word_tokenize(sentence)  \n",
        "    #print(tokens)\n",
        "    sentence_tmp = \"\"\n",
        "    for word,pos in nltk.pos_tag(tokens):\n",
        "        if type(word) == str:\n",
        "            word = word.lower()\n",
        "            \n",
        "        if not pos == \"DT\":\n",
        "            #print(pos)\n",
        "            sentence_tmp+=(lemmatizer.lemmatize(word)) + \" \"  \n",
        "    #print(sentence_tmp)\n",
        "    return sentence_tmp\n",
        "\n",
        "def extract_features(sentences):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    pre_features = [[],[]]\n",
        "\n",
        "    counter=-1\n",
        "    \n",
        "    #print(sentences)\n",
        "    for sentence in sentences:\n",
        "        counter+=1\n",
        "\n",
        "        sentence = preProcess(sentence)\n",
        "\n",
        "        nouns = [] #empty to array to hold all nouns\n",
        "        possesives = []\n",
        "        adverbs = []\n",
        "        adjectives = []\n",
        "        verbs = []\n",
        "        digrms = []\n",
        "        questionWords = []\n",
        "\n",
        "        tokens = nltk.word_tokenize(sentence)\n",
        "        \n",
        "        for word,pos in nltk.pos_tag(tokens):\n",
        "            if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n",
        "                nouns.append(word)\n",
        "            elif (pos == 'WDT' or pos == 'WP' or pos == 'WRB'):\n",
        "                questionWords.append(word)                 \n",
        "            elif (pos == 'POS'):\n",
        "                possesives.append(word)\n",
        "            elif (pos == 'RB' or pos == 'RBR' or pos == 'RBS'):\n",
        "                adverbs.append(word)\n",
        "            elif (pos == 'JJ' or pos == 'JJR' or pos == 'JJS'):\n",
        "                adjectives.append(word)                \n",
        "            elif (pos == 'VB' or pos == 'VBD' or pos == 'VBG' or pos == 'VBN' or pos == 'VBP' or pos == 'VBZ'):\n",
        "                verbs.append(word)   \n",
        "\n",
        "        \n",
        "        bigrm = nltk.bigrams(tokens)\n",
        "        for i in bigrm:\n",
        "            digrms.append(\" \".join(i))\n",
        "        #print(digrms)\n",
        "        \n",
        "        \n",
        "        from nltk.corpus import stopwords  \n",
        "        stop_words = stopwords.words('english')\n",
        "        list_words = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "        pre_features[counter].append(nouns) #0\n",
        "        pre_features[counter].append(possesives) #1\n",
        "        pre_features[counter].append(adverbs) #2\n",
        "        pre_features[counter].append(adjectives) #3\n",
        "        pre_features[counter].append(verbs) #4\n",
        "        pre_features[counter].append(digrms) #5\n",
        "        pre_features[counter].append(questionWords) #6\n",
        "        pre_features[counter].append(list(list_words)) #7\n",
        "\n",
        "\n",
        "\n",
        "    #print(pre_features[0])\n",
        "    #print(pre_features[1])\n",
        "\n",
        "    features = []\n",
        "\n",
        "    for x in [0,2,3,4,6,7]:\n",
        "        features.append(getSynonymsIndex(pre_features[0][x], pre_features[1][x]))\n",
        "\n",
        "    for x in [1,5]:\n",
        "        features.append(getMatchingIndex(pre_features[0][x], pre_features[1][x]))\n",
        "\n",
        "    return(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLBq6Un1QKj6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "77167ffd-2870-4ec0-ed4e-90a6fa73ed14"
      },
      "source": [
        "sentence1 = \"Bring the wine for me slowly\" \n",
        "sentence2 = \"to bring wine calmly\"\n",
        "sentences = []\n",
        "sentence1 = preProcess(sentence1)\n",
        "sentence2 = preProcess(sentence2)\n",
        "\n",
        "sentences.append(sentence1)\n",
        "sentences.append(sentence2)\n",
        "print(extract_features(sentences))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6666666666666666, 0.0, 0.5, 1.0, 0.5, 0.6666666666666666, 0.5, 0.2857142857142857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtLgOeoLSa92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0893e8d4-fb92-4b8c-d58a-22d8e4c8e845"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eShHQjkQZN8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!cp /content/gdrive/My\\ Drive/Colab\\ Notebooks/project10x/train.tsv /content/gdrive/My\\ Drive/Colab\\ Notebooks/project1/glue_data/QQP/train.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bittku6_QLze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d2c472a8-d842-4be1-ad85-af450be53abc"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "#path = os.path.join(os.getcwd(),\"project1\",\"glue_data\",\"QQP\")\n",
        "\n",
        "\n",
        "path = '/content/gdrive/My Drive/Colab Notebooks/project1/glue_data/QQP'\n",
        "       \n",
        "read_train = pd.read_csv(os.path.join(path,\"train.tsv\"),sep=\"\\t\")\n",
        "read_test = pd.read_csv(os.path.join(path,\"test.tsv\"),sep=\"\\t\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NElB7xQUTVSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python3 /content/gdrive/My\\ Drive/Colab\\ Notebooks/project1/download_glue_repo/download_glue_data.py --data_dir /content/gdrive/My\\ Drive/Colab\\ Notebooks/project1/glue_data/ --tasks QQP\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKSv8FGqRWzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "outputId": "db33eda9-8d73-471b-f348-a2d149530561"
      },
      "source": [
        "print(read_test.head())\n",
        "read_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id  ...                                          question2\n",
            "0   0  ...  Do you think that if Donald Trump were elected...\n",
            "1   1  ...  What are the top ten Consumer-to-Business E-co...\n",
            "2   2  ...  Why do people ask Quora questions instead of j...\n",
            "3   3  ...                           Is social trade geniune?\n",
            "4   4  ...  If universe and space is expanding? Does that ...\n",
            "\n",
            "[5 rows x 3 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133273</td>\n",
              "      <td>213221</td>\n",
              "      <td>213222.0</td>\n",
              "      <td>How is the life of a math student? Could you d...</td>\n",
              "      <td>Which level of prepration is enough for the ex...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>402555</td>\n",
              "      <td>536040</td>\n",
              "      <td>536041.0</td>\n",
              "      <td>How do I control my horny emotions?</td>\n",
              "      <td>How do you control your horniness?</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>360472</td>\n",
              "      <td>364011</td>\n",
              "      <td>490273.0</td>\n",
              "      <td>What causes stool color to change to yellow?</td>\n",
              "      <td>What can cause stool to come out as little balls?</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>150662</td>\n",
              "      <td>155721</td>\n",
              "      <td>7256.0</td>\n",
              "      <td>What can one do after MBBS?</td>\n",
              "      <td>What do i do after my MBBS ?</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>183004</td>\n",
              "      <td>279958</td>\n",
              "      <td>279959.0</td>\n",
              "      <td>Where can I find a power outlet for my laptop ...</td>\n",
              "      <td>Would a second airport in Sydney, Australia be...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    qid1  ...  is_duplicate Unnamed: 6\n",
              "0  133273  213221  ...             0        NaN\n",
              "1  402555  536040  ...             1        NaN\n",
              "2  360472  364011  ...             0        NaN\n",
              "3  150662  155721  ...             1        NaN\n",
              "4  183004  279958  ...             0        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI9j04JLRbKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_trainx = pd.DataFrame(read_train.iloc[:,3:5])\n",
        "df_trainy = pd.DataFrame(read_train.iloc[:,5])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-_7juSrRcyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "61ff6f66-212c-4cb3-dfb8-6fc6f0efdda7"
      },
      "source": [
        "print(df_trainx.shape)\n",
        "print(df_trainy.shape)\n",
        "#print(df_trainx.head())\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363194, 2)\n",
            "(363194, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IegmQj3jXB6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfW4Adv2Redg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 868
        },
        "outputId": "dce7d537-501d-4015-e2bf-229a1544576e"
      },
      "source": [
        "import time\n",
        "count=0\n",
        "dfx = []\n",
        "to_remove = []\n",
        "\n",
        "start = time.time()\n",
        "for i in range(df_trainx.shape[0]):\n",
        "    try:\n",
        "        sentences = list(df_trainx.iloc[i])\n",
        "        feature = extract_features(sentences)\n",
        "    except:\n",
        "        print(i)\n",
        "        to_remove.append(i)\n",
        "        continue\n",
        "    \n",
        "    #print(feature)\n",
        "    dfx.append(feature)\n",
        "    count+=1\n",
        "    if count%20000 == 0:\n",
        "        end = time.time()\n",
        "        diff = end-start\n",
        "        progress = (count/363194)*100\n",
        "        print(\"Done : {}%\".format(progress))\n",
        "        print(\"Estimated time left : {} min\".format((100 - progress)/progress*diff/60))\n",
        "        \n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done : 5.50669889921089%\n",
            "Estimated time left : 24.284752174142604 min\n",
            "36732\n",
            "37801\n",
            "Done : 11.01339779842178%\n",
            "Estimated time left : 22.325586780832612 min\n",
            "Done : 16.52009669763267%\n",
            "Estimated time left : 20.801433356588948 min\n",
            "Done : 22.02679559684356%\n",
            "Estimated time left : 19.334730380911232 min\n",
            "97828\n",
            "Done : 27.533494496054452%\n",
            "Estimated time left : 17.945312401145056 min\n",
            "Done : 33.04019339526534%\n",
            "Estimated time left : 16.532739021907318 min\n",
            "130155\n",
            "131430\n",
            "139005\n",
            "Done : 38.54689229447623%\n",
            "Estimated time left : 15.154494432256222 min\n",
            "Done : 44.05359119368712%\n",
            "Estimated time left : 13.798412530579917 min\n",
            "Done : 49.560290092898015%\n",
            "Estimated time left : 12.41098335898086 min\n",
            "Done : 55.066988992108904%\n",
            "Estimated time left : 11.041490737712262 min\n",
            "Done : 60.57368789131979%\n",
            "Estimated time left : 9.687847673717917 min\n",
            "228383\n",
            "Done : 66.08038679053068%\n",
            "Estimated time left : 8.335097324394052 min\n",
            "248378\n",
            "Done : 71.58708568974157%\n",
            "Estimated time left : 6.973508876398801 min\n",
            "Done : 77.09378458895246%\n",
            "Estimated time left : 5.618039545101552 min\n",
            "Done : 82.60048348816335%\n",
            "Estimated time left : 4.267987464330833 min\n",
            "300441\n",
            "309621\n",
            "Done : 88.10718238737424%\n",
            "Estimated time left : 2.917440367394985 min\n",
            "328697\n",
            "Done : 93.61388128658513%\n",
            "Estimated time left : 1.5660650360494979 min\n",
            "355333\n",
            "Done : 99.12058018579603%\n",
            "Estimated time left : 0.21555580347778405 min\n",
            "361570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHlNhUVGVnJB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfx = pd.DataFrame(dfx, columns = ['nouns', 'adverbs', 'adjectives',\n",
        "                                   'verbs','questionWords', 'words',\n",
        "                                   'possesives', 'digrms'])        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQc3huoUbLU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "8233ae34-f66e-49eb-eab1-85aecb34f226"
      },
      "source": [
        "print(dfx.head())\n",
        "#print(dfy.head())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      nouns  adverbs  adjectives  ...     words  possesives    digrms\n",
            "0  0.000000      0.5         0.0  ...  0.000000         0.5  0.000000\n",
            "1  0.000000      0.5         0.5  ...  0.400000         0.5  0.181818\n",
            "2  0.400000      0.5         0.0  ...  0.400000         0.5  0.125000\n",
            "3  1.000000      0.5         0.5  ...  0.666667         0.5  0.181818\n",
            "4  0.153846      0.5         0.0  ...  0.200000         0.5  0.000000\n",
            "\n",
            "[5 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBiKx_DzRf5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df_trainy.drop(df_trainy.index[to_remove], inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGhV8xzOkXiC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f1513178-e954-43fc-957f-804957dacae5"
      },
      "source": [
        "\n",
        "\n",
        "print(dfx.shape)\n",
        "print(df_trainy.shape)\n",
        "\n",
        "#print(dfy.head())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363181, 9)\n",
            "(363194, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjspUAXdk3Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "colab_dir = '/content/gdrive/My Drive/Colab Notebooks/'\n",
        "dfy = df_trainy.astype('bool')\n",
        "#dfx.to_csv(colab_dir + 'project10x/train_dfx.csv')\n",
        "#dfy.to_csv(colab_dir + 'project10x/train_dfy.csv')\n",
        "\n",
        "dfx = pd.read_csv(colab_dir + 'project10x/train_dfx.csv')\n",
        "dfy = pd.read_csv(colab_dir + 'project10x/train_dfy.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re4meOK0XfJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "xnn = []\n",
        "for row in dfx.digrms:\n",
        "    if(row>0.5):\n",
        "        xnn.append(1.0)\n",
        "    else:\n",
        "        xnn.append(0.0)\n",
        "        \n",
        "xn = pd.DataFrame(xnn,columns = ['questionWords'] )\n",
        "print(xn.head())\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "x = xn\n",
        "y = dfy.is_duplicate\n",
        "plt.scatter(x, y)\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "x = dfx.nouns\n",
        "y = dfy.is_duplicate\n",
        "plt.scatter(x, y)\n",
        "\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG17oXRfnIWU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "cce6b945-cfc3-4bef-c560-b8eada1ea851"
      },
      "source": [
        "\n",
        "dfx = dfx.iloc[:,1:]\n",
        "dfy = dfy.iloc[:,1]\n",
        "print(dfx.shape)\n",
        "print(dfy.shape)\n",
        "print(dfx[20000:20005])\n",
        "print(dfy[20000:20005])\n",
        "\n",
        "#trainx.iloc[20000:20005,:])\n",
        "#print(df_trainy.iloc[20000:20005,:])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(363181, 8)\n",
            "(363181,)\n",
            "          nouns  adverbs  adjectives  ...     words  possesives    digrms\n",
            "20000  1.000000      0.5    1.000000  ...  1.000000         0.5  0.615385\n",
            "20001  0.285714      0.4    0.666667  ...  0.428571         0.5  0.142857\n",
            "20002  0.800000      0.5    0.000000  ...  0.500000         0.5  0.153846\n",
            "20003  0.333333      0.0    0.500000  ...  0.222222         0.5  0.000000\n",
            "20004  0.571429      0.0    0.500000  ...  0.666667         0.5  0.153846\n",
            "\n",
            "[5 rows x 8 columns]\n",
            "20000    False\n",
            "20001    False\n",
            "20002    False\n",
            "20003    False\n",
            "20004    False\n",
            "Name: is_duplicate, dtype: bool\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4nyJzTjR_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "754cf496-a844-45be-d08e-e1fd2b6fb8c1"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "modelLR = LogisticRegression()\n",
        "modelLR.fit(dfx,dfy)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
              "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
              "          tol=0.0001, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLakrp1BRhTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "26a1f270-58d9-4a75-f151-5b561669782e"
      },
      "source": [
        "q1 = \"what is computer?\"\n",
        "q2 = \"what are advantage of computer?\"\n",
        "\n",
        "def predictOutput(q1,q2,model):\n",
        "    q=[q1,q2]\n",
        "    #print(\"hku\")\n",
        "    test_x = [extract_features(q)]\n",
        "    test_x = pd.DataFrame(test_x, columns = ['nouns', 'adverbs', 'adjectives',\n",
        "                                   'verbs', 'words', 'possesives',\n",
        "                                   'digrms', 'questionWords'])  \n",
        "    \n",
        "    print(model.predict_proba(test_x)[0][1])\n",
        "    \n",
        "    print(model.predict_proba(test_x)[0][1] >= 0.80)\n",
        "    return (model.predict(test_x))\n",
        "\n",
        "#RandomForestClassifier(n_estimators=num_trees, random_state=9)\n",
        "print(predictOutput(q1,q2,modelLR))\n",
        "'''\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    print(predictOutput(q1,q2,model))\n",
        "'''\n",
        "print(\"done\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8365232914580376\n",
            "True\n",
            "[ True]\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiS87zG64GvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "69b35257-192f-4228-ce99-7479ddc972b7"
      },
      "source": [
        "import pickle\n",
        "filename = '/content/gdrive/My Drive/Colab Notebooks/project10x/finalized_model.sav'\n",
        "pickle.dump(modelLR, open(filename, 'wb'))\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = predictOutput(q1,q2,loaded_model)\n",
        "print(result)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8365232914580376\n",
            "True\n",
            "[ True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2IphFN9nX56",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "01dbf1c8-508d-4891-b2e4-9f58856c3c78"
      },
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import numpy as np\n",
        "num_trees = 50\n",
        "test_size = 0.1\n",
        "seed=9\n",
        "\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(random_state=9)))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier(random_state=9)))\n",
        "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, random_state=9)))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC(random_state=9)))\n",
        "\n",
        "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(dfx),\n",
        "                                                                                          np.array(dfy),\n",
        "                                                                                          test_size=test_size,\n",
        "                                                                                          random_state=seed)\n",
        "scoring = \"accuracy\"\n",
        "results = []\n",
        "names = []                                                                                          \n",
        "# 5-fold cross validation\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=5, random_state=7)\n",
        "    print(kfold)\n",
        "    cv_results = cross_val_score(model, trainDataGlobal,\n",
        "                                 trainLabelsGlobal, cv=kfold,\n",
        "                                 scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)                                                                                          \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KFold(n_splits=5, random_state=7, shuffle=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LR: 0.772632 (0.001377)\n",
            "KFold(n_splits=5, random_state=7, shuffle=False)\n",
            "LDA: 0.772629 (0.001372)\n",
            "KFold(n_splits=5, random_state=7, shuffle=False)\n",
            "KNN: 0.731373 (0.003681)\n",
            "KFold(n_splits=5, random_state=7, shuffle=False)\n",
            "CART: 0.679183 (0.001318)\n",
            "KFold(n_splits=5, random_state=7, shuffle=False)\n",
            "RF: 0.742635 (0.001451)\n",
            "KFold(n_splits=5, random_state=7, shuffle=False)\n",
            "NB: 0.759617 (0.008185)\n",
            "KFold(n_splits=5, random_state=7, shuffle=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_EhP7-w3nZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQOkKONr3Ymp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKfQnmIg3Yhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llt2ZpwyRP76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)\n",
        "\n",
        "\n",
        "from sklearn.externals import joblib\n",
        "filename = 'finalized_model.sav'\n",
        "joblib.dump(model, filename)\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "loaded_model = joblib.load(filename)\n",
        "result = loaded_model.score(X_test, Y_test)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c9eIwr5IAop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('ML algorithm comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usHe46X6rRHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmukdF8NL8yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-tJZsgqr1O-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9wcPe4uMf_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwz3TMnOMwKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwNqZxxyMnFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovuRQBl2Mrbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}